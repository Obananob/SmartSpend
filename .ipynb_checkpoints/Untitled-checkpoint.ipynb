{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be3a519-eea9-4f37-97ed-7ad2b9563e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782fd832-6b04-4525-9eae-9b6372f597c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7293114-5cd4-44c0-9642-74acf75ffa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "country_data = pd.read_csv('country_data.csv')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# check the dataset overview\n",
    "country_data.head()\n",
    "\n",
    "\n",
    "# The dataset consists of 10 variables, with 9 being numeric and 1 categorical. To effectively cluster the data, I will first remove the country column, as it is a categorical variable and does not align with the requirements for clustering. Following this, I will scale the numeric features to optimize the performance of the clustering algorithm. Scaling is crucial as it removes potential biases caused by differing units of measurement across variables, thereby enhancing the consistency and accuracy of the clustering results.\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# check the dataset information\n",
    "country_data.info()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# check for duplicate\n",
    "country_data.duplicated().sum()\n",
    "\n",
    "\n",
    "# The dataset consists of 167 non-null observations, with each variable correctly assigned to its appropriate data type. Additionally, there are no duplicate entries present, ensuring the dataset's integrity and consistency for analysis.\n",
    "\n",
    "# ### Data Preprocessing\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# Removing the 'country' column for clustering as it is a categorical identifier\n",
    "X = country_data.drop(columns=['country'])\n",
    "X.head()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# Standardizing the features to improve clustering performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "X_scaled\n",
    "\n",
    "\n",
    "# ## Build KMeans Clustering Model\n",
    "\n",
    "# I will apply KMeans clustering to categorize the observations in the dataset into different groups. KMeans is a widely-used unsupervised learning technique that organizes data points into clusters based on their similarities. The goal is to divide the data into a predetermined number of clusters, with each data point assigned to the cluster whose centroid is closest.\n",
    "# \n",
    "# Each predicted cluster represents a potential number of labels for the countries. To assess the quality of these clusters, I will compute the silhouette score for each cluster. Silhouette score is a measure used to evaluate the quality of clusters in clustering algorithms like K-means, hierarchical clustering, or DBSCAN. It quantifies how well each data point fits into its assigned cluster (cohesion) compared to neighboring clusters (separation). Higher silhouette scores imply better clustering.\n",
    "# \n",
    "# \n",
    "# The Silhouette Coefficient ranges from -1 to +1 with a value close to +1 indicates that the object is well-matched to its own cluster and poorly matched to neighboring clusters, a value close to 0 indicates that the object is on or very close to the decision boundary between two neighboring clusters while a value close to -1 indicates that the object may have been assigned to the wrong cluster. it is calculated with a formula   \\[\n",
    "#   s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "#   \\]\n",
    "#   Where:\n",
    "#   - \\(a(i)\\) is the average distance between point \\(i\\) and all other points in the same cluster (intra-cluster distance).\n",
    "#   - \\(b(i)\\) is the average distance between point \\(i\\) and all points in the nearest cluster that it is not a part of (nearest-cluster distance).\n",
    "# \n",
    "# \n",
    "# Once I have computed the silhouette score for each cluster, I will store them in a variable called Silhouette scores. Then, I will create a line plot of Silhouette scores against the number of clusters. The cluster with the highest silhouette score indicates the optimal number of driver categories.\n",
    "\n",
    "# ### Define the necessary functions\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def calculate_silhouette_score(X_data, max_clusters):\n",
    "    # silhoutte score as the metric to get the optimal number of clusters\n",
    "        \n",
    "    # create a variable to store the silhoutte score for each cluster\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in range(2, max_clusters+1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init = 10)\n",
    "        cluster_labels = kmeans.fit_predict(X_data)  # predict the number of cluster (different labels)\n",
    "        silhouette_avg = silhouette_score(X_data, cluster_labels)  # Evaluate the quality of clusters in clustering \n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "    return silhouette_scores\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def plot_silhouette_score(silhouette_scores):\n",
    "    # visualize the silhouette scores \n",
    "    plt.plot(range(2, max_clusters+1), silhouette_scores)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Score for each Cluster')\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "def print_optimal_cluster(silhouette_scores):\n",
    "    # Choose the optimal number of clusters with the highest silhouette score\n",
    "    optimal_num_clusters = silhouette_scores.index(max(silhouette_scores)) + 2\n",
    "    print(\"Optimal number of clusters:\", optimal_num_clusters)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "def cluster_dataset(df, X_data, silhouette_scores):\n",
    "    # Choose the optimal number of clusters with the highest silhouette score\n",
    "    optimal_num_clusters = silhouette_scores.index(max(silhouette_scores)) + 2\n",
    "    \n",
    "    # Perform K-means clustering with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=optimal_num_clusters, random_state=42, n_init = 10)\n",
    "    cluster_labels = kmeans.fit_predict(X_data)\n",
    "    \n",
    "    # Create a label for each entry in the dataset \n",
    "    df['cluster'] = cluster_labels\n",
    "    \n",
    "    return df, cluster_labels, kmeans\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "def visualise_clusters(X_data, cluster_labels, kmeans):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    # Visualize the distribution of each category using just two features for simplicity\n",
    "    plt.scatter(X_data[:, 0], X_data[:, 1], c=cluster_labels, cmap='Accent_r', s=20)\n",
    "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='x')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('K-means Clustering')\n",
    "\n",
    "\n",
    "# In[111]:\n",
    "\n",
    "\n",
    "def analyse_data_cluster(df):\n",
    "    # Analyzing Cluster Characteristics\n",
    "    # Descriptive statistics of clusters to understand their characteristics\n",
    "    cluster_summary = df.groupby('cluster').mean(numeric_only=True)\n",
    "    print(\"Cluster Summary:\")\n",
    "    print(cluster_summary)\n",
    "\n",
    "\n",
    "# ### Cluster Base on Two Features\n",
    "\n",
    "# In[112]:\n",
    "\n",
    "\n",
    "# define the number features to use in clustering\n",
    "num_feature = 2\n",
    "\n",
    "# define the maximum number of cluster\n",
    "max_clusters = 10\n",
    "\n",
    "# extract the number of features of interest from the whole data\n",
    "X_data = X_scaled[:, :num_feature]\n",
    "\n",
    "# compute the silhouette score\n",
    "sil_score = calculate_silhouette_score(X_data, max_clusters = max_clusters)\n",
    "\n",
    "\n",
    "# In[113]:\n",
    "\n",
    "\n",
    "# plot silhouette score to get the optimal number of cluster \n",
    "plot_silhouette_score(silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "\n",
    "# print optimal number of cluster obtained\n",
    "print_optimal_cluster(sil_score)\n",
    "\n",
    "\n",
    "# In[115]:\n",
    "\n",
    "\n",
    "# assign each observation to its cluster \n",
    "df, cluster_labels, kmeans = cluster_dataset(df = country_data, X_data = X_data, silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "# visualize the cluster using the first two features\n",
    "visualise_clusters(X_data = X_data, cluster_labels= cluster_labels, kmeans= kmeans)\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "\n",
    "# calculate the descriptive statistics of each cluster to see how they are compare\n",
    "analyse_data_cluster(df)\n",
    "\n",
    "\n",
    "# ### Cluster base on three features\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "# define the number features to use in clustering\n",
    "num_feature = 3\n",
    "\n",
    "# define the maximum number of cluster\n",
    "max_clusters = 10\n",
    "\n",
    "# extract the number of features of interest from the whole data\n",
    "X_data = X_scaled[:, :num_feature]\n",
    "\n",
    "# compute the silhouette score\n",
    "sil_score = calculate_silhouette_score(X_data, max_clusters = max_clusters)\n",
    "\n",
    "# plot silhouette score to get the optimal number of cluster \n",
    "plot_silhouette_score(silhouette_scores = sil_score)\n",
    "\n",
    "# print optimal number of cluster obtained\n",
    "print_optimal_cluster(sil_score)\n",
    "\n",
    "# assign each observation to its cluster \n",
    "df, cluster_labels, kmeans = cluster_dataset(df = country_data, X_data = X_data, silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[120]:\n",
    "\n",
    "\n",
    "# visualize the cluster using the first two features\n",
    "visualise_clusters(X_data = X_data, cluster_labels= cluster_labels, kmeans= kmeans)\n",
    "\n",
    "\n",
    "# In[121]:\n",
    "\n",
    "\n",
    "# calculate the descriptive statistics of each cluster to see how they are compare\n",
    "analyse_data_cluster(df)\n",
    "\n",
    "\n",
    "# ### Cluster base on four features\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "\n",
    "# define the number features to use in clustering\n",
    "num_feature = 4\n",
    "\n",
    "# define the maximum number of cluster\n",
    "max_clusters = 10\n",
    "\n",
    "# extract the number of features of interest from the whole data\n",
    "X_data = X_scaled[:, :num_feature]\n",
    "\n",
    "# compute the silhouette score\n",
    "sil_score = calculate_silhouette_score(X_data, max_clusters = max_clusters)\n",
    "\n",
    "# plot silhouette score to get the optimal number of cluster \n",
    "plot_silhouette_score(silhouette_scores = sil_score)\n",
    "\n",
    "# print optimal number of cluster obtained\n",
    "print_optimal_cluster(sil_score)\n",
    "\n",
    "# assign each observation to its cluster \n",
    "df, cluster_labels, kmeans = cluster_dataset(df = country_data, X_data = X_data, silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[123]:\n",
    "\n",
    "\n",
    "# visualize the cluster using the first two features\n",
    "visualise_clusters(X_data = X_data, cluster_labels= cluster_labels, kmeans= kmeans)\n",
    "\n",
    "\n",
    "# In[124]:\n",
    "\n",
    "\n",
    "# calculate the descriptive statistics of each cluster to see how they are compare\n",
    "analyse_data_cluster(df)\n",
    "\n",
    "\n",
    "# ### Cluster by 7 features\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "# define the number features to use in clustering\n",
    "num_feature = 7\n",
    "\n",
    "# define the maximum number of cluster\n",
    "max_clusters = 10\n",
    "\n",
    "# extract the number of features of interest from the whole data\n",
    "X_data = X_scaled[:, :num_feature]\n",
    "\n",
    "# compute the silhouette score\n",
    "sil_score = calculate_silhouette_score(X_data, max_clusters = max_clusters)\n",
    "\n",
    "# plot silhouette score to get the optimal number of cluster \n",
    "plot_silhouette_score(silhouette_scores = sil_score)\n",
    "\n",
    "# print optimal number of cluster obtained\n",
    "print_optimal_cluster(sil_score)\n",
    "\n",
    "# assign each observation to its cluster \n",
    "df, cluster_labels, kmeans = cluster_dataset(df = country_data, X_data = X_data, silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[129]:\n",
    "\n",
    "\n",
    "# visualize the cluster using the first two features\n",
    "visualise_clusters(X_data = X_data, cluster_labels= cluster_labels, kmeans= kmeans)\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "\n",
    "# calculate the descriptive statistics of each cluster to see how they are compare\n",
    "analyse_data_cluster(df)\n",
    "\n",
    "\n",
    "# ### Cluster by all the features\n",
    "\n",
    "# In[125]:\n",
    "\n",
    "\n",
    "# define the number features to use in clustering\n",
    "num_feature = 10\n",
    "\n",
    "# define the maximum number of cluster\n",
    "max_clusters = 10\n",
    "\n",
    "# extract the number of features of interest from the whole data\n",
    "X_data = X_scaled[:, :num_feature]\n",
    "\n",
    "# compute the silhouette score\n",
    "sil_score = calculate_silhouette_score(X_data, max_clusters = max_clusters)\n",
    "\n",
    "# plot silhouette score to get the optimal number of cluster \n",
    "plot_silhouette_score(silhouette_scores = sil_score)\n",
    "\n",
    "# print optimal number of cluster obtained\n",
    "print_optimal_cluster(sil_score)\n",
    "\n",
    "# assign each observation to its cluster \n",
    "df, cluster_labels, kmeans = cluster_dataset(df = country_data, X_data = X_data, silhouette_scores = sil_score)\n",
    "\n",
    "\n",
    "# In[126]:\n",
    "\n",
    "\n",
    "# visualize the cluster using the first two features\n",
    "visualise_clusters(X_data = X_data, cluster_labels= cluster_labels, kmeans= kmeans)\n",
    "\n",
    "\n",
    "# In[127]:\n",
    "\n",
    "\n",
    "# calculate the descriptive statistics of each cluster to see how they are compare\n",
    "analyse_data_cluster(df)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
